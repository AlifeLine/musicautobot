{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.numpy_encode import *\n",
    "from src.utils.file_processing import process_all, process_file\n",
    "from src.config import *\n",
    "from src.music_transformer import *\n",
    "from src.multitask_transformer import *\n",
    "from src.utils.stacked_dataloader import StackedDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultitaskTransformer Training\n",
    "\n",
    "Multitask Training is an extension of [MusicTransformer](../music_transformer/Train.ipynb).\n",
    "\n",
    "Instead a basic language model that predicts the next word...\n",
    "\n",
    "We train on multiple tasks\n",
    "* [Next Word](../music_transformer/Train.ipynb)\n",
    "* [Bert Mask](https://arxiv.org/abs/1810.04805)\n",
    "* [Sequence to Sequence Translation](http://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "This gives a more generalized model and also let's you do some really cool [predictions](Generate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end training pipeline \n",
    "\n",
    "1. Create and encode dataset\n",
    "2. Initialize Transformer MOdel\n",
    "3. Train\n",
    "4. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of your midi files\n",
    "midi_path = Path('data/midi/examples')\n",
    "midi_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Location to save dataset\n",
    "data_path = Path('data/numpy')\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_save_name = 'musicitem_data_save.pkl'\n",
    "s2s_data_save_name = 'multiitem_data_save.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gather midi dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all your midi data is in `musicautobot/data/midi` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a pretty good dataset with lots of midi data:  \n",
    "https://www.reddit.com/r/datasets/comments/3akhxy/the_largest_midi_collection_on_the_internet/\n",
    "\n",
    "Download the folder and unzip it to `data/midi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create dataset from MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_files = get_files(midi_path, '.mid', recurse=True); len(midi_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Create NextWord/Mask Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [Midi2ItemProcessor()]\n",
    "data = MusicDataBunch.from_files(midi_files, data_path, processors=processors, \n",
    "                                 encode_position=True, dl_tfms=mask_lm_tfm, \n",
    "                                 bptt=5, bs=2)\n",
    "data.save(data_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msk': {'x': tensor([[  4, 145,  61, 145,   4],\n",
       "          [ 64, 145,  61, 145,   4]]), 'pos': tensor([[8, 8, 8, 8, 8],\n",
       "          [8, 8, 8, 8, 8]])}, 'lm': {'x': tensor([[139,  64, 145,  61, 145],\n",
       "          [139,  64, 145,  61, 145]]), 'pos': tensor([[8, 8, 8, 8, 8],\n",
       "          [8, 8, 8, 8, 8]])}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = data.one_batch(); xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key:\n",
    "* 'msk' = masked input\n",
    "* 'lm' = next word input\n",
    "* 'pos' = timestepped postional encoding. This is in addition to relative positional encoding\n",
    "\n",
    "Note: MultitaskTransformer trains on both the masked input ('msk') and next word input ('lm') at the same time.\n",
    "\n",
    "The encoder is trained on the 'msk' data, while the decoder is trained on 'lm' data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Create sequence to sequence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = [Midi2MultitrackProcessor()]\n",
    "s2s_data = MusicDataBunch.from_files(midi_files, data_path, processors=processors, \n",
    "                                     preloader_cls=S2SPreloader, list_cls=S2SItemList,\n",
    "                                     dl_tfms=melody_chord_tfm,\n",
    "                                     bptt=5, bs=2)\n",
    "s2s_data.save(s2s_data_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c2m': {'enc': tensor([[  5,   1,  61, 145,  59],\n",
       "          [  5,   1,  57, 153,  53]]), 'enc_pos': tensor([[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]]), 'dec': tensor([[  6,   1,  85, 143,   8],\n",
       "          [  6,   1,  77, 139,   8]]), 'dec_pos': tensor([[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]])}, 'm2c': {'enc': tensor([[  6,   1,  85, 143,   8],\n",
       "          [  6,   1,  77, 139,   8]]), 'enc_pos': tensor([[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]]), 'dec': tensor([[  5,   1,  61, 145,  59],\n",
       "          [  5,   1,  57, 153,  53]]), 'dec_pos': tensor([[0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0]])}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = s2s_data.one_batch(); xb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key:\n",
    "* 'c2m' = chord2melody translation\n",
    " * enc = chord\n",
    " * dec = melody\n",
    "* 'm2c' = next word input\n",
    " * enc = melody\n",
    " * dec = chord\n",
    "* 'pos' = timestepped postional encoding. Gives the model a better reference when translating\n",
    "\n",
    "Note: MultitaskTransformer trains both translations ('m2c' and 'c2m') at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "batch_size = 2\n",
    "bptt = 128\n",
    "\n",
    "lm_data = load_data(data_path, data_save_name, \n",
    "                    bs=batch_size, bptt=bptt, encode_position=True,\n",
    "                    dl_tfms=mask_lm_tfm)\n",
    "\n",
    "s2s_data = load_data(data_path, s2s_data_save_name, \n",
    "                     bs=batch_size//2, bptt=bptt,\n",
    "                     preloader_cls=S2SPreloader, dl_tfms=melody_chord_tfm)\n",
    "\n",
    "# Combine both dataloaders so we can train multiple tasks at the same time\n",
    "data = StackedDataBunch([lm_data, s2s_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "config = multitask_config(); config\n",
    "\n",
    "learn = multitask_model_learner(data, config.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "---\n",
    "See [Generate.ipynb](Generate.ipynb) to use a pretrained model and generate better predictions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_files = get_files(midi_path, '.mid', recurse=True)\n",
    "midi_file = Path('data/single_bar_example.mid'); midi_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word = nw_predict_from_midi(learn, 'midi_file', n_words=20, seed_len=8); next_word.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_melody = s2s_predict_from_midi(learn, midi_file, n_words=20, seed_len=4, pred_melody=True); pred_melody.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_notes = mask_predict_from_midi(learn, midi_file, n_words=20, predict_notes=True); pred_notes.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
